{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English Sentence Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UYRJ9F5wV5j1",
        "UxKOmFRdrfVf",
        "9BMofmnKjDfs",
        "UyI2HAB1yFk_",
        "Es9_NCfcyJ_6"
      ],
      "mount_file_id": "1prLalDT_maKhMli9pm_VXOCr1S6ZDGvA",
      "authorship_tag": "ABX9TyO94IFgdnL4QiQKp3SfqArT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravi-prakash1907/Data-Structures-and-Algo/blob/main/Submissions/Group%20Projects/Project3/English_Sentence_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEqW0B7yvl4G"
      },
      "source": [
        "# **Project 3**\n",
        "\n",
        "## English Sentence Generator\n",
        "\n",
        "<!--\n",
        "_**([Final Report Here!!](#))**_\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbBKO7yB7xZL"
      },
      "source": [
        "### _Libraries_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm8H5oQWv0Xx"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import re"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYRJ9F5wV5j1"
      },
      "source": [
        "## Processing Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izOs7jo4jvp-"
      },
      "source": [
        "### Processing Level 1\n",
        "\n",
        "1. Taking Input  \n",
        "2. Converting to Lower Case  \n",
        "3. Resolving for Abbriviation  \n",
        "4. Removing Negation  \n",
        "\n",
        "_(Step 1, 2, 3 and 4)_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2hF4khWRIIV"
      },
      "source": [
        "### Processing Level 2\n",
        "\n",
        "1. Resolving for Interrogatives  \n",
        "2. Remove Stopping/Ending Symbol (. ! ? : ; etc..)\n",
        "\n",
        "_(Step 5, 6)_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxKOmFRdrfVf"
      },
      "source": [
        "### Processing Level 3\n",
        "\n",
        "_Split mutiple sentances on Conjunctions:_  \n",
        "  - That  \n",
        "  - But  \n",
        "  - While  \n",
        "  - Meanwhile  \n",
        "  - Still\n",
        "  - Before  \n",
        "\n",
        "_Remove Interjections:_  \n",
        "  - oh!  \n",
        "  - yess!!  \n",
        "  etc..  \n",
        "  \n",
        "  _(Step 7)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4ejdz1rsXS7"
      },
      "source": [
        "## to remove interjections\n",
        "def removeInterjections(sentance):\n",
        "  wordList = sentance.split(\" \")\n",
        "  foundInterjections = []\n",
        "  for word in wordList:\n",
        "    if word[-2:] == \"!!\" or word[-1] == \"!\":\n",
        "      foundInterjections.append(word)\n",
        "  \n",
        "  # removing found interjections\n",
        "  for interjection in foundInterjections:\n",
        "    wordList.remove(interjection)\n",
        "  \n",
        "  newSentence = listToSentance(wordList)\n",
        "  return newSentence\n",
        "\n",
        "## to extract only one sentance from grouped form\n",
        "def multipleSentances(sentance):\n",
        "  wordList = sentance.split(\" \")\n",
        "  foundConjunctions = hasWordsFrom(conjunctions, wordList)\n",
        "\n",
        "  if foundConjunctions:\n",
        "    twoSubSentences = sentance.split(foundConjunctions[0])\n",
        "    twoSubSentences = removeBlanks(twoSubSentences)\n",
        "    commonSub = []\n",
        "    commonSub.extend(articles)\n",
        "    commonSub.extend(pluralPronouns)\n",
        "    commonSub.extend(singlelPronouns)\n",
        "    \n",
        "    hasDualSentance = False\n",
        "    for thisSubSentance in twoSubSentences:\n",
        "      if hasWordsFrom(allHelpingVerbs, thisSubSentance) or hasWordsFrom(commonSub, thisSubSentance):\n",
        "        hasDualSentance = True\n",
        "      else:\n",
        "        hasDualSentance = False\n",
        "      \n",
        "    if hasDualSentance:\n",
        "      return twoSubSentences[0]\n",
        "    \n",
        "  return sentance\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHuC3HYTRghV"
      },
      "source": [
        "### Processing Level 4\n",
        "\n",
        "**Initial Splitting** _(if consists Helping Verb)_  \n",
        "\n",
        "* ```['sub', 'HV', 'verb', 'obj']```\n",
        "* ```['sub', 'HV', 'obj']```\n",
        "\n",
        "\n",
        "Based on the type of sentence :  \n",
        "_(except present/past simple)_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWXypml1hnRE"
      },
      "source": [
        "### Processing Level 5\n",
        "\n",
        "**Initial Splitting** _(without Helping Verb)_  \n",
        "\n",
        "* ```['sub', 'verb', 'obj']```\n",
        "* ```['sub', 'obj']```\n",
        "\n",
        "_(Step 8.2)_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7Ct6tTkxvx9"
      },
      "source": [
        "### Processing Level 6\n",
        "\n",
        "_Splitting based on the type of sentence_  \n",
        "\n",
        "**Strusture**  \n",
        "\n",
        "* ```['Subject', 'Helping Verb', 'Verb', 'Object']```\n",
        "\n",
        "_(in some cases, few of the parts can be blank)_  \n",
        "\n",
        "_(Step 8)_  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foyO7TpHyotA"
      },
      "source": [
        "## Sentance to list creater:\n",
        "\n",
        "```['Sun'  +  'H.V.'  +  'Verb'  +  'Obj']```\n",
        "\n",
        "##  Processing Done in following manner\n",
        "\n",
        "**Steps:**  \n",
        "1. Get Sentance (Input)  \n",
        "2. Convert to Lower/Upper Case  \n",
        "3. Resolve for Abbriviation  \n",
        "4. Remove Negation  \n",
        "6. Remove Stopping Symbol (. ! ? : ; etc..)  \n",
        "7. Split into multiple sentances on Conjunctions\n",
        "8. Split the Sentance and Store in Dictionary  \n",
        "  - _Parts of Sentance:_  \n",
        "    a) Subject  \n",
        "    b) Helping Verb  \n",
        "    c) Verb  \n",
        "    d) Object  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbvjvZsyG8u8"
      },
      "source": [
        "class sentenceSplitter:\n",
        "  def __init__(self, limit = 50):\n",
        "    ## global variables for class\n",
        "    self.__articles = ['a', 'an', 'the']\n",
        "    self.__pluralPronouns = ['some', 'any', 'these', 'their', 'our', 'those', 'them', 'they', 'you', 'i', 'we']\n",
        "    self.__singlelPronouns = ['he', 'she','his', 'her', 'my', 'this', 'that', 'it']\n",
        "    self.__conjunctions = ['that', 'but', 'while', 'meanwhile', 'still', 'before']\n",
        "    self.__allHelpingVerbs = ['is', 'am', 'are', 'was', 'were', 'shall', 'will', 'should', 'would', 'might', 'could', 'have', 'has', 'had', 'can', 'may' 'must', 'did' 'do', 'does']\n",
        "\n",
        "\n",
        "    self.__specialHV = self.__allHelpingVerbs[:7]    \n",
        "    self.__firstPriority = self.__allHelpingVerbs[:5]\n",
        "    self.__secondPriority = self.__allHelpingVerbs[5:11]\n",
        "    self.__thirdPriority = self.__allHelpingVerbs[11:14]\n",
        "    self.__forthPriority = self.__allHelpingVerbs[14:]\n",
        "\n",
        "    ## list of lists (splitted sentances)\n",
        "    self.__corpus = []\n",
        "    self.__maxSize = limit   ## maximum sentences\n",
        "    self.currentSize = 0\n",
        "\n",
        "\n",
        "  ###########################\n",
        "  ###   Private Methods   ###\n",
        "  ###########################\n",
        "  def __updateSize(self):\n",
        "    self.currentSize = len(self.__corpus)\n",
        "    return True\n",
        "  \n",
        "  def __isInsertionPossible(self):\n",
        "    if self.__maxSize > self.currentSize:\n",
        "      return True\n",
        "    else:\n",
        "      return False\n",
        "  \n",
        "  def __addInCorpus(self, formattedSentence):\n",
        "    self.__corpus.append(formattedSentence)\n",
        "    self.__updateSize()\n",
        "    return True\n",
        "\n",
        "  ###########################\n",
        "\n",
        "  ## returns elements of 'allWords' that are in 'findIn'\n",
        "  def __hasWordsFrom(self, allWords, findIn):\n",
        "    found = []\n",
        "    for searched in allWords:\n",
        "      if searched in findIn:\n",
        "        found.append(searched)\n",
        "    if len(found) > 0:\n",
        "      return found\n",
        "    return False\n",
        "\n",
        "  ## remove unnecessary space in beg or end of string and emptyStrings too\n",
        "  def __removeBlanks(self, wordGroup):\n",
        "    for wordIndex in range(len(wordGroup)):\n",
        "      if wordGroup[wordIndex] == '':\n",
        "        continue\n",
        "      while wordGroup[wordIndex][0] == \" \":\n",
        "        wordGroup[wordIndex] = wordGroup[wordIndex][1:]\n",
        "      while wordGroup[wordIndex][-1] == \" \":\n",
        "        wordGroup[wordIndex] = wordGroup[wordIndex][:-1]\n",
        "    \n",
        "    return wordGroup\n",
        "\n",
        "  ## List of words to sentance\n",
        "  def __listToSentance(self, buildingBlocks):\n",
        "    buildingBlocks = self.__removeBlanks(buildingBlocks)\n",
        "    newSentance = \"\"\n",
        "    for word in buildingBlocks:\n",
        "      newSentance += word + \" \"\n",
        "    return newSentance[:-1]   # last letter is space (from for-loop)  \n",
        "  \n",
        "  ###########################\n",
        "\n",
        "  ### Processing Level 4 ###\n",
        "  \"\"\"\n",
        "  present/past continuous tense and statement\n",
        "  \"\"\"  \n",
        "  def __commonPresentPast(self, sentance, hVerb): # 'he is boy' + pContinuous\n",
        "    Subject = Object = Verb = ''\n",
        "    wordWise = sentance.split(\" \")\n",
        "    \n",
        "    indexOfHVNext = wordWise.index(hVerb)+1\n",
        "    Subject = self.__listToSentance(wordWise[:indexOfHVNext-1])\n",
        "    if wordWise[indexOfHVNext][-3:] == 'ing':\n",
        "      Verb = wordWise[indexOfHVNext]\n",
        "      if indexOfHVNext < len(wordWise):\n",
        "        Object = self.__listToSentance(wordWise[indexOfHVNext+1:])\n",
        "    else:\n",
        "      if indexOfHVNext < len(wordWise):\n",
        "        Object = self.__listToSentance(wordWise[indexOfHVNext:])\n",
        "      \n",
        "    return [Subject, hVerb, Verb, Object]\n",
        "\n",
        "  \"\"\"\n",
        "  present/past perfect/perfect-continuous tense\n",
        "  \"\"\"  \n",
        "  def __perfectPresentPast(self, sentance, hVerb):\n",
        "    Subject = Object = Verb = ''\n",
        "    wordWise = sentance.split(\" \")\n",
        "\n",
        "    gotHV = self.__hasWordsFrom(['been'], wordWise)\n",
        "    if gotHV:\n",
        "      indexOfHVNext = wordWise.index('been')+1\n",
        "      indexOfSubNext = wordWise.index(hVerb)\n",
        "      hVerb += \" been\"\n",
        "\n",
        "      if wordWise[indexOfHVNext][-3:] == 'ing':\n",
        "        Subject = self.__listToSentance(wordWise[:indexOfSubNext])\n",
        "        Verb = wordWise[indexOfHVNext]\n",
        "        if indexOfHVNext < len(wordWise):\n",
        "          Object = self.__listToSentance(wordWise[indexOfHVNext+1:])\n",
        "    else:\n",
        "      indexOfHVNext = wordWise.index(hVerb)+1\n",
        "      Subject = self.__listToSentance(wordWise[:indexOfHVNext-1])\n",
        "      if indexOfHVNext <= len(wordWise):\n",
        "        Verb = wordWise[indexOfHVNext]\n",
        "        if indexOfHVNext < len(wordWise):\n",
        "          Object = self.__listToSentance(wordWise[indexOfHVNext+1:])\n",
        "\n",
        "    return [Subject, hVerb, Verb, Object]      \n",
        "\n",
        "  \"\"\"\n",
        "  future tense and statement\n",
        "  \"\"\"  \n",
        "  def __futureTense(self, sentance, hVerb):\n",
        "    Subject = Object = Verb = ''\n",
        "    wordWise = sentance.split(\" \")\n",
        "\n",
        "    if self.__hasWordsFrom(['have'], wordWise):\n",
        "      gotHV = self.__hasWordsFrom(['been'], wordWise)\n",
        "      if gotHV:\n",
        "        indexOfHVNext = wordWise.index('been')+1\n",
        "        indexOfSubNext = wordWise.index(hVerb)\n",
        "        hVerb += \" have been\"\n",
        "\n",
        "        if wordWise[indexOfHVNext][-3:] == 'ing':\n",
        "          Subject = self.__listToSentance(wordWise[:indexOfSubNext])\n",
        "          Verb = wordWise[indexOfHVNext]\n",
        "          if indexOfHVNext < len(wordWise):\n",
        "            Object = self.__listToSentance(wordWise[indexOfHVNext+1:]) \n",
        "      else:\n",
        "        indexOfHVNext = wordWise.index('have')+1\n",
        "        indexOfSubNext = wordWise.index(hVerb)\n",
        "        hVerb += \" have\"\n",
        "        \n",
        "        Subject = self.__listToSentance(wordWise[:indexOfSubNext])\n",
        "        Verb = wordWise[indexOfHVNext]\n",
        "        if indexOfHVNext < len(wordWise):\n",
        "          Object = self.__listToSentance(wordWise[indexOfHVNext+1:])  \n",
        "    else:\n",
        "      gotHV = self.__hasWordsFrom(['be'], wordWise)\n",
        "      if gotHV:\n",
        "        indexOfHVNext = wordWise.index('be')+1\n",
        "        indexOfSubNext = wordWise.index(hVerb)\n",
        "        hVerb += \" be\"\n",
        "        indexOfHVNext = wordWise.index('be')+1\n",
        "        if wordWise[indexOfHVNext][-3:] == 'ing':\n",
        "          Subject = self.__listToSentance(wordWise[:indexOfSubNext])\n",
        "          Verb = wordWise[indexOfHVNext]\n",
        "          if indexOfHVNext < len(wordWise):\n",
        "            Object = self.__listToSentance(wordWise[indexOfHVNext+1:])\n",
        "      else:\n",
        "        indexOfHVNext = wordWise.index(hVerb)+1\n",
        "        Subject = self.__listToSentance(wordWise[:wordWise.index(hVerb)])\n",
        "        Verb = wordWise[indexOfHVNext]\n",
        "        if indexOfHVNext < len(wordWise):\n",
        "          Object = self.__listToSentance(wordWise[indexOfHVNext+1:])\n",
        "    \n",
        "    return [Subject, hVerb, Verb, Object]\n",
        "\n",
        "  \"\"\"\n",
        "  some other continuous tense and guessing statement\n",
        "  \"\"\"  \n",
        "  def __someContinuousPlus(self, sentance, hVerb):\n",
        "    Subject = Object = Verb = ''\n",
        "    wordWise = sentance.split(\" \")\n",
        "\n",
        "    gotHV = self.__hasWordsFrom(['be'], wordWise)\n",
        "    if gotHV:\n",
        "      indexOfHVNext = wordWise.index('be')+1\n",
        "      indexOfSubNext = wordWise.index(hVerb)\n",
        "      hVerb += \" be\"\n",
        "\n",
        "      indexOfHVNext = wordWise.index('be')+1\n",
        "      if wordWise[indexOfHVNext][-3:] == 'ing':\n",
        "        Subject = self.__listToSentance(wordWise[:indexOfSubNext])\n",
        "        Verb = wordWise[indexOfHVNext]\n",
        "        if indexOfHVNext < len(wordWise):\n",
        "          Object = self.__listToSentance(wordWise[indexOfHVNext+1:]) \n",
        "    else:\n",
        "      indexOfHVNext = wordWise.index(hVerb)+1\n",
        "      Subject = self.__listToSentance(wordWise[:wordWise.index(hVerb)])\n",
        "      Verb = wordWise[indexOfHVNext]\n",
        "      if indexOfHVNext < len(wordWise):\n",
        "        Object = self.__listToSentance(wordWise[indexOfHVNext+1:])\n",
        "    \n",
        "    return [Subject, hVerb, Verb, Object]\n",
        "\n",
        "\n",
        "  ### Processing Level 5 ###\n",
        "  \"\"\"\n",
        "  **Initial Splitting** (without Helping Verb)\n",
        "\n",
        "  * ```['sub', 'verb', 'obj']```\n",
        "  * ```['sub', 'obj']````\n",
        "  \"\"\"\n",
        "  ###   Finishing Level 5\n",
        "  def __splitSimple(self, sentance = 'the cow grazes the grass'):\n",
        "    wordList = sentance.split(\" \")\n",
        "    totalWords = len(wordList)\n",
        "    Subject = Verb = Object = ''\n",
        "\n",
        "    if totalWords <= 2:\n",
        "      Subject = wordList[0]\n",
        "      if (Subject in self.__singlelPronouns) and (wordList[1][-1] == 's' and wordList[1][-2:] not in ['us', 'os', 'ss', 'is', 'as']):\n",
        "        Verb = wordList[1]\n",
        "      else:\n",
        "        Object = wordList[1]\n",
        "    else:\n",
        "      # checking for Simple Past\n",
        "      if sentance[-2:] == 'ed' or 'ed ' in sentance:\n",
        "        for word in wordList:\n",
        "          if 'ed' in word or 'ed ' in word:\n",
        "            Subject = self.__listToSentance(wordList[:wordList.index(word)])\n",
        "            Verb = word\n",
        "            Object = self.__listToSentance(wordList[wordList.index(word)+1:])\n",
        "            break\n",
        "        \n",
        "      # checking for Simple Present (mainly)\n",
        "      else:\n",
        "        sEsEndingWords = []\n",
        "        for word in wordList:\n",
        "          if (word[-2:] == 'es') or (word[-1] == 's' and not (word[-2:] == 'us' or word[-2:] == 'ss')):\n",
        "            sEsEndingWords.append(word)\n",
        "\n",
        "        usedArticles = self.__hasWordsFrom(self.__articles, wordList)\n",
        "\n",
        "        # if consisits articles\n",
        "        if usedArticles:\n",
        "          if wordList[0] in self.__articles and len(sEsEndingWords) == 1:\n",
        "            #wordList.remove(wordList[0])\n",
        "            wordList[0] = self.__listToSentance(wordList[:2])\n",
        "            wordList.remove(wordList[1])\n",
        "            totalWords -= 1\n",
        "            subEndIndex = wordList.index(sEsEndingWords[0])\n",
        "            if sEsEndingWords[0] == wordList[0][len(sEsEndingWords[0]):]:\n",
        "              Subject = self.__listToSentance(wordList[:subEndIndex+1])\n",
        "              Verb = self.__listToSentance(wordList[subEndIndex+1:])    \n",
        "              Object = self.__listToSentance(wordList[wordList.index(Verb)+1:]) \n",
        "            else:\n",
        "              Subject = self.__listToSentance(wordList[:subEndIndex])\n",
        "              Verb = sEsEndingWords[0]\n",
        "              Object = self.__listToSentance(wordList[subEndIndex+1:])\n",
        "          else:\n",
        "            objBegIndex = wordList.index(usedArticles[0])\n",
        "            singleSub = self.__hasWordsFrom(self.__singlelPronouns, wordList)\n",
        "            if singleSub:\n",
        "              subEndIndex = wordList.index(singleSub[0]) + 1\n",
        "              Subject = self.__listToSentance(wordList[:subEndIndex])\n",
        "              Verb = wordList[subEndIndex]\n",
        "              Object = self.__listToSentance(wordList[objBegIndex:])\n",
        "            else:\n",
        "              Subject = self.__listToSentance(wordList[:objBegIndex-1])\n",
        "              Verb = wordList[objBegIndex-1]\n",
        "              Object = self.__listToSentance(wordList[objBegIndex:])\n",
        "        \n",
        "        else:\n",
        "          if len(sEsEndingWords) == 0:\n",
        "            pluralSub = self.__hasWordsFrom(self.__pluralPronouns, wordList)\n",
        "            if pluralSub:\n",
        "              subEndIndex = wordList.index(pluralSub[0]) + 1\n",
        "            elif ' and ' in sentance:\n",
        "              subEndIndex = wordList.index('and') + 1\n",
        "            else:\n",
        "              subEndIndex = 1\n",
        "            Subject = self.__listToSentance(wordList[:subEndIndex])\n",
        "            Verb = self.__listToSentance(wordList[subEndIndex:subEndIndex+1]) \n",
        "            Object = self.__listToSentance(wordList[subEndIndex+1:]) \n",
        "          else:\n",
        "            if wordList.index(sEsEndingWords[0]) == 0:\n",
        "              Subject = self.__listToSentance(wordList[:1])\n",
        "              Verb = self.__listToSentance(wordList[1:2]) \n",
        "              Object = self.__listToSentance(wordList[2:]) \n",
        "            else:\n",
        "              singleSub = self.__hasWordsFrom(self.__singlelPronouns, wordList)\n",
        "              if singleSub:\n",
        "                subEndIndex = wordList.index(singleSub[0]) + 1\n",
        "              else:\n",
        "                subEndIndex = 1\n",
        "              Subject = self.__listToSentance(wordList[:subEndIndex])\n",
        "              Verb = self.__listToSentance(wordList[subEndIndex:subEndIndex+1])\n",
        "              \n",
        "              if len(wordList) > subEndIndex+1:\n",
        "                Object = self.__listToSentance(wordList[subEndIndex+1:])\n",
        "\n",
        "    return [Subject, Verb, Object]\n",
        "\n",
        "  \n",
        "\n",
        "  #################################################################\n",
        "  #################################################################\n",
        "\n",
        "\n",
        "  ###########################\n",
        "  ###   Public Methods   ###\n",
        "  ###########################\n",
        "\n",
        "  ###########################\n",
        "  ### Processing Level 1 ###\n",
        "  \"\"\"\n",
        "  1. Resolving Whitespaces and Converting to Lower Case  \n",
        "  2. Resolving for Abbriviation  \n",
        "  3. Removing Negation  \n",
        "  \"\"\"\n",
        "  ###########################\n",
        "\n",
        "  def initCleaning(self, sentance):\n",
        "    sentance = re.sub(' +', ' ', sentance)\n",
        "    sentance = sentance.lower()\n",
        "    return sentance\n",
        "\n",
        "  \n",
        "  # resolving for abbreviations\n",
        "  def resolveAbbr(self, sentance):\n",
        "    if '\\'' in sentance:\n",
        "      splittedSentance = sentance.split(\" \")\n",
        "\n",
        "      for index in range(0, len(splittedSentance)):\n",
        "        word = splittedSentance[index]\n",
        "\n",
        "        # abbriviated 'not'\n",
        "        if word[-3:] == 'n\\'t':\n",
        "          if word == 'can\\'t':\n",
        "            word = 'can not'\n",
        "          elif word == 'ain\\'t':\n",
        "            word = 'are not'  \n",
        "          elif word == 'won\\'t':\n",
        "            word = 'will not'\n",
        "          elif word == 'shan\\'t':\n",
        "            word = 'shall not'\n",
        "          else:\n",
        "            word = word[:-3] + \" not\"\n",
        "        \n",
        "        # abbriviated 'ing'\n",
        "        if word[-3:] == 'in\\'':\n",
        "          word = word[:-1] + 'g'\n",
        "        \n",
        "        # abbriviated helping verbs\n",
        "        abbrHVerbs = {'m':'am', 's':'is', 're':'are', 'll':'will', 've':'have', 'd':'had'}\n",
        "        if \"'\" in word:\n",
        "          flag = False\n",
        "          brokenWord = word.split('\\'')\n",
        "          for abbr in list(abbrHVerbs.keys()):\n",
        "            if  abbr == brokenWord[1]:\n",
        "              brokenWord[1] = abbrHVerbs[abbr]\n",
        "              flag = True\n",
        "\n",
        "          if flag:\n",
        "            word = self.__listToSentance(brokenWord)\n",
        "          else:\n",
        "            word = brokenWord[0] + '\\'' + brokenWord[1]\n",
        "        \n",
        "        splittedSentance[index] = word\n",
        "\n",
        "      resolvedTense = self.__listToSentance(splittedSentance)\n",
        "      return resolvedTense\n",
        "\n",
        "    return sentance\n",
        "\n",
        "\n",
        "  ## Removing Negation\n",
        "  def negationRemover(self, sentance):\n",
        "    if 'not' in sentance:\n",
        "      begIndex = sentance.find(\"not\")\n",
        "      sentance = sentance[:begIndex-1] + sentance[begIndex+3:]\n",
        "      sentance = self.negationRemover(sentance)\n",
        "    return sentance\n",
        "\n",
        "\n",
        "  ###########################\n",
        "  ### Processing Level 2 ###\n",
        "  \"\"\"\n",
        "  1. Resolving for Interrogatives  \n",
        "  2. Remove Stopping/Ending Symbol (. ! ? : ; etc..)\n",
        "  \"\"\"\n",
        "  ###########################\n",
        "  \n",
        "  ## Yet to be implemented\n",
        "  def removeQuestion(self, sentance):\n",
        "    #print(\"Interrogative to normal sentance converter is yet to be impleented!\\n\")\n",
        "    return sentance\n",
        "\n",
        "  def removeStops(self, sentance):\n",
        "    if not sentance[-1].isalpha() and not sentance[-1].isdigit():\n",
        "      sentance = self.removeStops(sentance[:-1])\n",
        "    return sentance\n",
        "\n",
        "\n",
        "  ###########################\n",
        "  ### Processing Level 3 ###\n",
        "  \"\"\"\n",
        "  1. Split mutiple sentances on Conjunctions:\n",
        "    - That, But, While, Meanwhile, Still, Before etc.. \n",
        "\n",
        "  2. Remove Interjections:\n",
        "    - oh!, yess!! etc.. \n",
        "  \"\"\"\n",
        "  ###########################\n",
        "    \n",
        "  ## to remove interjections\n",
        "  def removeInterjections(self, sentance):\n",
        "    wordList = sentance.split(\" \")\n",
        "    foundInterjections = []\n",
        "    for word in wordList:\n",
        "      if word[-2:] == \"!!\" or word[-1] == \"!\":\n",
        "        foundInterjections.append(word)\n",
        "    \n",
        "    # removing found interjections\n",
        "    for interjection in foundInterjections:\n",
        "      wordList.remove(interjection)\n",
        "    \n",
        "    newSentence = self.__listToSentance(wordList)\n",
        "    return newSentence\n",
        "\n",
        "  ## to extract only one sentance from grouped form\n",
        "  def multipleSentances(self, sentance):\n",
        "    wordList = sentance.split(\" \")\n",
        "    foundConjunctions = self.__hasWordsFrom(conjunctions, wordList)\n",
        "\n",
        "    if foundConjunctions:\n",
        "      twoSubSentences = sentance.split(foundConjunctions[0])\n",
        "      twoSubSentences = self.__removeBlanks(twoSubSentences)\n",
        "      commonSub = []\n",
        "      commonSub.extend(articles)\n",
        "      commonSub.extend(pluralPronouns)\n",
        "      commonSub.extend(singlelPronouns)\n",
        "      \n",
        "      hasDualSentance = False\n",
        "      for thisSubSentance in twoSubSentences:\n",
        "        if self.__hasWordsFrom(self.__allHelpingVerbs, thisSubSentance) or self.__hasWordsFrom(commonSub, thisSubSentance):\n",
        "          hasDualSentance = True\n",
        "        else:\n",
        "          hasDualSentance = False\n",
        "        \n",
        "      if hasDualSentance:\n",
        "        return twoSubSentences[0]\n",
        "      \n",
        "    return sentance\n",
        "\n",
        "\n",
        "  ###########################\n",
        "  ### Processing Level 6 ###\n",
        "  \"\"\"\n",
        "  Splitting based on the type of sentence  \n",
        "  ```['Subject', 'Helping Verb', 'Verb', 'Object']```\n",
        "\n",
        "  (in some cases, few of the parts can be blank)\n",
        "  \"\"\"\n",
        "  ###########################\n",
        "  def consistsHelpingVerb(self, sentance = \"he goes\"):\n",
        "    splittedForm = ['', '', '', '']\n",
        "    wordWise = sentance.split(\" \")\n",
        "    gotHV = self.__hasWordsFrom(self.__firstPriority, wordWise)\n",
        "    if gotHV:\n",
        "      splittedForm = self.__commonPresentPast(sentance, gotHV[0])              # 'he is boy' or he is running'.\n",
        "    \n",
        "    elif self.__hasWordsFrom(self.__secondPriority, wordWise):\n",
        "      gotHV = self.__hasWordsFrom(self.__secondPriority, wordWise)\n",
        "      splittedForm = self.__futureTense(sentance, gotHV[0]) \n",
        "    \n",
        "    elif self.__hasWordsFrom(self.__thirdPriority, wordWise):\n",
        "      gotHV = self.__hasWordsFrom(self.__thirdPriority, wordWise)\n",
        "      splittedForm = self.__perfectPresentPast(sentance, gotHV[0])             # perfect    has \n",
        "    \n",
        "    elif self.__hasWordsFrom(self.__forthPriority, wordWise):\n",
        "      gotHV = self.__hasWordsFrom(self.__forthPriority, wordWise)\n",
        "      splittedForm = self.__someContinuousPlus(sentance, gotHV[0])       ## may be +ing\n",
        "    \n",
        "    else:\n",
        "      HV = ''\n",
        "      splittedForm = self.__splitSimple(sentance)\n",
        "      splittedForm.insert(1,HV)\n",
        "    \n",
        "    return splittedForm\n",
        "\n",
        "\n",
        "\n",
        "  ###########################\n",
        "  ### Driver Function ###\n",
        "  \"\"\"\n",
        "  Splitting based on the type of sentence  \n",
        "  ```['Subject', 'Helping Verb', 'Verb', 'Object']```\n",
        "  \"\"\"\n",
        "  ###########################\n",
        "  def convertToList(self, textData = \"It\\'s a sample.\"):\n",
        "    aSentance = self.initCleaning(textData)    \n",
        "    processedTense = self.resolveAbbr(aSentance)\n",
        "    processedTense = self.negationRemover(processedTense)\n",
        "    cleanSentance = self.removeStops(processedTense)\n",
        "\n",
        "    interjectionRemoval = self.removeInterjections(cleanSentance)\n",
        "    extractedSentence = self.multipleSentances(interjectionRemoval)\n",
        "\n",
        "    fullSentance = self.consistsHelpingVerb(extractedSentence) \n",
        "\n",
        "    self.__addInCorpus(fullSentance)\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "  #################################################################\n",
        "  #################################################################\n",
        "\n",
        "\n",
        "  \n",
        "  ## Reading a sentence\n",
        "  def loadSentances(self, fileName = None):\n",
        "    if fileName is None:\n",
        "      fileName = input(\"Enter the path to the text (.txt) file: \")\n",
        "      if fileName[-4:] != \".txt\":\n",
        "        print(\"Invalid file path! Try next time!\")\n",
        "    else:\n",
        "      opened = open(fileName, 'r')\n",
        "      textData = opened.readlines()\n",
        "      opened.close()\n",
        "\n",
        "      if len(textData) > 0:\n",
        "        for thisSentence in textData:\n",
        "          if self.__isInsertionPossible():\n",
        "            self.convertToList(thisSentence)\n",
        "          else:\n",
        "            print(\"50 sentences loaded!\\n\")\n",
        "            return True\n",
        "        print(len(textData),\"sentences loaded!\\n\")\n",
        "        return True\n",
        "      else:\n",
        "        print(\"Error in file! No sentence Found!!\\n\")\n",
        "        return False\n",
        "\n",
        "\n",
        "  ## Printing the available corpus\n",
        "  def printSentenceList(self):\n",
        "    if self.currentSize > 0:\n",
        "      print(\"\\n--------------------------\\nListing the\",self.currentSize,\"sentances:\\n--------------------------\\n\")\n",
        "      counter = 1\n",
        "      for grouppedSentence in self.__corpus:\n",
        "        if counter < 10:\n",
        "          print(\"0\"+str(counter),\")\",end = \" \")\n",
        "        else:\n",
        "          print(counter,\")\",end = \" \")\n",
        "        print(grouppedSentence)\n",
        "        counter += 1\n",
        "    else:\n",
        "      print(\"Empty Corpus!!\")\n",
        "\n",
        "\n",
        "  ## get returns number of loaded available sentances\n",
        "\n"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QVpSnUbO_Vs",
        "outputId": "3fe938ed-6482-473f-f6a1-2ac11e5aaf5a"
      },
      "source": [
        "thisSplitter = sentenceSplitter()\n",
        "thisSplitter.loadSentances(\"basics.txt\")\n",
        "thisSplitter.printSentenceList()"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12 sentences loaded!\n",
            "\n",
            "\n",
            "--------------------------\n",
            "Listing the 12 sentances:\n",
            "--------------------------\n",
            "\n",
            "01 ) ['he', '', 'runs', 'fast']\n",
            "02 ) ['he', 'is', 'running', 'fast']\n",
            "03 ) ['he', 'has', 'run', 'fast']\n",
            "04 ) ['he', 'has been', 'running', 'fast, since 3pm']\n",
            "05 ) ['he', '', 'ran', 'fast']\n",
            "06 ) ['he', 'was', 'running', 'fast']\n",
            "07 ) ['he', 'had', 'run', 'fast']\n",
            "08 ) ['he', 'had been', 'running', 'fast, since 3pm']\n",
            "09 ) ['he', 'will', 'run', 'fast']\n",
            "10 ) ['he', 'will be', 'running', 'fast']\n",
            "11 ) ['he', 'will have', 'run', 'fast']\n",
            "12 ) ['he', 'will have been', 'running', 'fast, since 3pm']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BMofmnKjDfs"
      },
      "source": [
        "## Storing in Tree\n",
        "\n",
        "**Steps:**  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEFNHPdcjKEg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH3_Apk8xroY"
      },
      "source": [
        "# **Users' Zone**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyI2HAB1yFk_"
      },
      "source": [
        "## Main-Menu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfHAuVHhy9NY"
      },
      "source": [
        "def menu():\n",
        "  # Printing Menu\n",
        "  print(\"\\nMain Menu:\")\n",
        "  print(\"\"\"----------\n",
        "        \\n1. Load Sentences  \\n2. Print List of Processed Sentences  \\n3. Generate Sentences \\n\n",
        "        \\n** Any other key to exit!!\\n\n",
        "        \"\"\")\n",
        "  return input(\"Enter your choice: \")"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es9_NCfcyJ_6"
      },
      "source": [
        "## Main-Function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6wDVKdTtUe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db749df5-b5c6-4538-ccbb-c7e414a18761"
      },
      "source": [
        "### To be Implemented\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  \n",
        "  ## Showing Menu\n",
        "\n",
        "  while (True): \n",
        "    clear_output()\n",
        "    choice = menu()\n",
        "    \n",
        "    print(\"Yet to be implemented!\\nMeet Soon!!!\")\n",
        "    break"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Main Menu:\n",
            "----------\n",
            "        \n",
            "1. Load Sentences  \n",
            "2. Print List of Processed Sentences  \n",
            "3. Generate Sentences \n",
            "\n",
            "        \n",
            "** Any other key to exit!!\n",
            "\n",
            "        \n",
            "Enter your choice: \n",
            "Yet to be implemented!\n",
            "Meet Soon!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7Pk5G50heCY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMsBT8zVhfM1"
      },
      "source": [
        "# **Experiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOUFh9MWhbPg"
      },
      "source": [
        "3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRzdv0S_ihA2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}