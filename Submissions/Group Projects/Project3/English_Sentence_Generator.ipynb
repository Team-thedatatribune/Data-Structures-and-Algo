{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English Sentence Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PbBKO7yB7xZL",
        "izOs7jo4jvp-",
        "E2hF4khWRIIV",
        "KLSf3Sh-fv3y",
        "ZWXypml1hnRE",
        "9BMofmnKjDfs",
        "rH3_Apk8xroY",
        "UyI2HAB1yFk_",
        "Es9_NCfcyJ_6"
      ],
      "mount_file_id": "1prLalDT_maKhMli9pm_VXOCr1S6ZDGvA",
      "authorship_tag": "ABX9TyNFnk/Iv717Vx5MEoNDMuDI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravi-prakash1907/Data-Structures-and-Algo/blob/main/Submissions/Group%20Projects/Project3/English_Sentence_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEqW0B7yvl4G"
      },
      "source": [
        "# **Project 3**\n",
        "\n",
        "## English Sentence Generator\n",
        "\n",
        "<!--\n",
        "_**([Final Report Here!!](#))**_\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbBKO7yB7xZL"
      },
      "source": [
        "### _Libraries_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm8H5oQWv0Xx"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foyO7TpHyotA"
      },
      "source": [
        "## Input Text Processing\n",
        "\n",
        "**Steps:**  \n",
        "1. Get Sentance (Input)  \n",
        "2. Convert to Lower/Upper Case  \n",
        "3. Resolve for Abbriviation (ain't, I've, can't...)  \n",
        "4. Remove Negation  \n",
        "5. Resolve for Interrogative  \n",
        "6. Remove Stopping Symbol (. ! ? : ; etc..)\n",
        "7. Split the Sentance and Store in Dictionary  \n",
        "  - _Parts of Sentance:_  \n",
        "    a) Subject  \n",
        "    b) Helping Verb  \n",
        "    c) Verb + Object  \n",
        "\n",
        "_(we can later split **b** in 2-levels and **c** in 2 saperate parts)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNhV9ozDoMah"
      },
      "source": [
        "## returns elements of 'allWords' that are in 'findIn'\n",
        "def hasWordsFrom(allWords, findIn):\n",
        "  found = []\n",
        "  for searched in allWords:\n",
        "    if searched in findIn:\n",
        "      found.append(searched)\n",
        "  if len(found) > 0:\n",
        "    return found\n",
        "  return False\n",
        "\n",
        "## returns indices of elements of 'allWords' that are in 'findIn'\n",
        "def hasWordsIndexFrom(allWords, findIn):\n",
        "  found = []\n",
        "  for searched in allWords:\n",
        "    for index in reange(len(findIn)):\n",
        "      if searched == findIn[index]:\n",
        "        found.append(index)\n",
        "  if len(found) > 0:\n",
        "    return found\n",
        "  return False\n",
        "\n",
        "## List of words to sentance\n",
        "def listToSentance(buildingBlocks):\n",
        "  newSentance = \"\"\n",
        "  for word in buildingBlocks:\n",
        "    newSentance += word\n",
        "    if newSentance[0] == \" \":\n",
        "      newSentance = newSentance[1:]\n",
        "    if newSentance[-1] == \" \":\n",
        "      newSentance = newSentance[:-1]\n",
        "    newSentance += \" \"\n",
        "  \n",
        "  return newSentance[:-1]   # last letter is space (from for-loop)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izOs7jo4jvp-"
      },
      "source": [
        "### Processing Level 1\n",
        "\n",
        "1. Taking Input  \n",
        "2. Converting to Lower Case  \n",
        "3. Resolving for Abbriviation  \n",
        "4. Removing Negation  \n",
        "\n",
        "_(Step 1, 2, 3 and 4)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6odzyxoihyU"
      },
      "source": [
        "## part of text data cleaner\n",
        "def toLower(sentance):\n",
        "  return sentance.lower()\n",
        "\n",
        "\n",
        "# resolving for abbreviations\n",
        "def resolveAbbr(sentance):\n",
        "  if '\\'' in sentance:\n",
        "    splittedSentance = sentance.split(\" \")\n",
        "\n",
        "    for index in range(0, len(splittedSentance)):\n",
        "      word = splittedSentance[index]\n",
        "\n",
        "      # abbriviated 'not'\n",
        "      if word[-3:] == 'n\\'t':\n",
        "        if word == 'can\\'t':\n",
        "          word = 'can not'\n",
        "        elif word == 'ain\\'t':\n",
        "          word = 'are not'  # or 'is not' too in some cases still it'll work for now\n",
        "        elif word == 'won\\'t':\n",
        "          word = 'will not'\n",
        "        elif word == 'shan\\'t':\n",
        "          word = 'shall not'\n",
        "        else:\n",
        "          word = word[:-3] + \" not\"\n",
        "      \n",
        "      # abbriviated 'ing'\n",
        "      if word[-3:] == 'in\\'':\n",
        "        word = word[:-1] + 'g'\n",
        "      \n",
        "      # abbriviated helping verbs\n",
        "      abbrHVerbs = {'m':'am', 's':'is', 're':'are', 'll':'will', 've':'have', 'd':'had'}\n",
        "      if \"'\" in word:\n",
        "        flag = False\n",
        "        brokenWord = word.split('\\'')\n",
        "        for abbr in list(abbrHVerbs.keys()):\n",
        "          if  abbr == brokenWord[1]:\n",
        "            brokenWord[1] = abbrHVerbs[abbr]\n",
        "            flag = True\n",
        "\n",
        "        if flag:\n",
        "          word = listToSentance(brokenWord)\n",
        "        else:\n",
        "          word = brokenWord[0] + '\\'' + brokenWord[1]\n",
        "      \n",
        "      splittedSentance[index] = word\n",
        "\n",
        "    resolvedTense = listToSentance(splittedSentance)\n",
        "    return resolvedTense\n",
        "\n",
        "  return sentance\n",
        "\n",
        "\n",
        "## Later we'll read sntances from some other source(s).\n",
        "def readSentance():\n",
        "  textData = input(\"Enter a sentance: \")\n",
        "  return textData\n",
        "\n",
        "\n",
        "## Removing Negation\n",
        "def negationRemover(sentance):\n",
        "  if 'not' in sentance:\n",
        "    begIndex = sentance.find(\"not\")\n",
        "    sentance = sentance[:begIndex-1] + sentance[begIndex+3:]\n",
        "    sentance = negationRemover(sentance)\n",
        "  return sentance\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2hF4khWRIIV"
      },
      "source": [
        "### Processing Level 2\n",
        "\n",
        "1. Resolving for Interrogatives  \n",
        "2. Remove Stopping Symbol (. ! ? : ; etc..)\n",
        "\n",
        "_(Step 5)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlnX-tBARX2H"
      },
      "source": [
        "## Yet to be implemented\n",
        "def removeQuestion(sentance):\n",
        "  print(\"Interrogative to normal sentance converter is yet to be impleented!\\n\")\n",
        "  return sentance\n",
        "\n",
        "def removeStops(sentance):\n",
        "  if not sentance[-1].isalpha() and not sentance[-1].isdigit():\n",
        "    sentance = removeStops(sentance[:-1])\n",
        "  return sentance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHuC3HYTRghV"
      },
      "source": [
        "### Processing Level 3\n",
        "\n",
        "**Initial Splitting** _(if consists Helping Verb)_  \n",
        "\n",
        "**Parts of Sentance:**  \n",
        "  - Subject + Helping Verb  \n",
        "  - Verb + Object  \n",
        "\n",
        "\n",
        "_(Step 6.1)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2yKUKwsdfhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b45ad9-2de7-4bbd-ba0c-a4dcfec0e540"
      },
      "source": [
        "## Building Blocks\n",
        "\n",
        "# splits as:  ['sub + HV', 'verb + obj']\n",
        "def splitOnHelpingVerb(sentance):\n",
        "  ## H.V. to split\n",
        "  firstPriority = ['is', 'am', 'are', 'was', 'were']\n",
        "  secondPriority = ['been', 'be']\n",
        "  thirdPriority = ['have']\n",
        "  forthPriority = ['shall', 'will', 'may', 'can', 'must', 'should', 'would', 'might', 'could', 'do', 'does', 'did', 'has', 'had']\n",
        "\n",
        "  helpingVerbs = [firstPriority, secondPriority, thirdPriority, forthPriority]\n",
        "  initSplit = []\n",
        "  splitted = False\n",
        "  \n",
        "  for priorityList in helpingVerbs:\n",
        "    for helpingVerb in priorityList:\n",
        "      if helpingVerb in sentance:\n",
        "        initSplit = sentance.split(helpingVerb)\n",
        "        initSplit[0] += helpingVerb\n",
        "        splitted = True\n",
        "        break\n",
        "    if splitted:\n",
        "      break\n",
        "  \n",
        "  return initSplit\n",
        "\n",
        "\n",
        "def consistsHelpingVerb(sentance = \"he goes\"):\n",
        "  ## Helping Verbs List\n",
        "  helpingVerbs = ['is', 'am', 'are', 'was', 'were', 'been', 'be', 'have', 'shall', 'will', 'may', 'can', 'must', 'should', 'would', 'might', 'could', 'do', 'does', 'did', 'has', 'had']\n",
        "  if hasWordsFrom(helpingVerbs, sentance.split(\" \")):\n",
        "    splittedForm = splitOnHelpingVerb(sentance)\n",
        "    return splittedForm,True\n",
        "  else:\n",
        "    HV = ''\n",
        "    splittedForm = splitSimple(sentance)\n",
        "    splittedForm.insert(1,HV)\n",
        "    return splittedForm,False\n",
        "\n",
        "#######################################\n",
        "\n",
        "## he is a bad boy, although he is ready for singing for now as it is already 10 o'clock\n",
        "consistsHelpingVerb()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['he', '', 'goes'], False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLSf3Sh-fv3y"
      },
      "source": [
        "### Processing Level 4\n",
        "\n",
        "**Secondary Splitting**  \n",
        "\n",
        "_Parts of **Subject + Helping Verb** :_  \n",
        "  - Subject  \n",
        "  - Helping Verb  \n",
        "\n",
        "_(Step 6.2)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7hjK8pwgbFf"
      },
      "source": [
        "## split [\"Sub\", \"helpingVerb / verb / verb+obj\"]\n",
        "def splitFromBeg(sentance, consistsHV = False):  # rename 'consistsHV'  --->  'helpingVerbs'\n",
        "  if len(sentance.split(\" \")) == 2:\n",
        "    return sentance.split(\" \")\n",
        "  \n",
        "  elif len(sentance.split(\" \")) > 2 and consistsHV:\n",
        "\n",
        "    #############################################################################\n",
        "    ####  this list can be feeded as input to the 'consistsHV'\n",
        "    firstPriority = ['is', 'am', 'are', 'was', 'were']\n",
        "    secondPriority = ['been', 'be']\n",
        "    thirdPriority = ['have']\n",
        "    forthPriority = ['shall', 'will', 'may', 'can', 'must', 'should', 'would', 'might', 'could', 'do', 'does', 'did', 'has', 'had']\n",
        "    \n",
        "    helpingVerbs = [forthPriority, thirdPriority, secondPriority, firstPriority]\n",
        "    #helpingVerbs = [secondPriority, thirdPriority, forthPriority, firstPriority]\n",
        "    #############################################################################\n",
        "\n",
        "    begSplitted = []\n",
        "    splitted = False\n",
        "    \n",
        "    for priorityList in helpingVerbs:\n",
        "      for helpingVerb in priorityList:\n",
        "        if helpingVerb in sentance:\n",
        "          begSplitted = sentance.split(helpingVerb)\n",
        "          begSplitted[1] = helpingVerb + begSplitted[1]\n",
        "          splitted = True\n",
        "          break\n",
        "      if splitted:\n",
        "        break\n",
        "    return begSplitted\n",
        "  else:\n",
        "    wordList = sentance.split(\" \")\n",
        "    print(\"Yet to be implemented for sentences without HV. (like: 'he goes.')\\nReturning word-list\")\n",
        "    return wordList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWXypml1hnRE"
      },
      "source": [
        "### Processing Level 5\n",
        "\n",
        "**Secondary Splitting** _(without HV)_  \n",
        "\n",
        "_Parts of **Subject + [Verb + Object**] :_  \n",
        "  - Subject\n",
        "  - Verb  \n",
        "  - Object  \n",
        "\n",
        "_(Step 6.5)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRuOg8zSiITu"
      },
      "source": [
        "def splitSimple(sentance = \"He works\"):\n",
        "  wordList = sentance.split(\" \")\n",
        "  totalWords = len(wordList)\n",
        "  \n",
        "  if totalWords <= 2:\n",
        "    return wordList\n",
        "  else:\n",
        "    Subject = Verb = Object = ''\n",
        "\n",
        "    # checking for Simple Past\n",
        "    if sentance[-2:] == 'ed' or 'ed ' in sentance:\n",
        "      for word in wordList:\n",
        "        if 'ed' in word or 'ed ' in word:\n",
        "          Subject = listToSentance(wordList[:wordList.index(word)])\n",
        "          Verb = word\n",
        "          Object = listToSentance(wordList[wordList.index(word)+1:])\n",
        "          break\n",
        "      \n",
        "    # checking for Simple Present (mainly)\n",
        "    else:\n",
        "      articles = ['a', 'an', 'the']\n",
        "      pluralPronouns = ['some', 'any', 'these', 'those', 'them', 'they', 'you', 'i', 'we']\n",
        "      singlelPronouns = ['this', 'that', 'it']  # Tackel more at :   http://grammar.ccc.commnet.edu/grammar/determiners/determiners.htm#:~:text=These%20categories%20of%20determiners%20are,any%2C%20etc.)%3B%20and%20demonstrative\n",
        "\n",
        "      sEsEndingWords = []\n",
        "      for word in wordList:\n",
        "        if (word[-2:] == 'es') or (word[-1] == 's' and not (word[-2:] == 'us' or word[-2:] == 'ss')):\n",
        "          sEsEndingWords.append(word)\n",
        "\n",
        "      usedArticles = hasWordsFrom(articles, wordList)\n",
        "\n",
        "      # if consisits articles\n",
        "      if usedArticles:\n",
        "        if wordList[0] in articles and len(sEsEndingWords) == 1:\n",
        "          wordList.remove(wordList[0])\n",
        "          totalWords -= 1\n",
        "          subEndIndex = wordList.index(sEsEndingWords[0])\n",
        "          if sEsEndingWords[0] == wordList[0]:\n",
        "            Subject = listToSentance(wordList[:subEndIndex+1])\n",
        "            Verb = listToSentance(wordList[subEndIndex+1:])    # includes object\n",
        "            Object = Verb # includes verb\n",
        "          else:\n",
        "            Subject = listToSentance(wordList[:subEndIndex])\n",
        "            Verb = sEsEndingWords[0]\n",
        "            Object = listToSentance(wordList[subEndIndex:])\n",
        "        else:\n",
        "          objBegIndex = wordList.index(usedArticles[0])\n",
        "          Subject = listToSentance(wordList[:objBegIndex-1])\n",
        "          Verb = wordList[objBegIndex-1]\n",
        "          Object = listToSentance(wordList[objBegIndex:])\n",
        "      \n",
        "      else:\n",
        "        if len(sEsEndingWords) == 0:\n",
        "          pluralSub = hasWordsFrom(pluralPronouns, wordList)\n",
        "          if pluralSub:\n",
        "            subEndIndex = wordList.index(pluralSub[0]) + 1\n",
        "          elif ' and ' in sentance:\n",
        "            subEndIndex = wordList.index('and') + 1\n",
        "          else:\n",
        "            subEndIndex = 1\n",
        "          Subject = listToSentance(wordList[:subEndIndex])\n",
        "          Verb = listToSentance(wordList[subEndIndex:subEndIndex+1])    # may includes object\n",
        "          Object = listToSentance(wordList[subEndIndex+1:])  # may includes verb\n",
        "        else:\n",
        "          if wordList.index(sEsEndingWords[0]) == 0:\n",
        "            Subject = listToSentance(wordList[:1])\n",
        "            Verb = listToSentance(wordList[1:2])    # includes object\n",
        "            Object = listToSentance(wordList[2:]) # includes verb\n",
        "          else:\n",
        "            singleSub = hasWordsFrom(singlelPronouns, wordList)\n",
        "            if singleSub:\n",
        "              subEndIndex = wordList.index(singleSub[0]) + 1\n",
        "            else:\n",
        "              subEndIndex = 1\n",
        "            Subject = listToSentance(wordList[:subEndIndex])\n",
        "            Verb = listToSentance(wordList[wordList.index(sEsEndingWords[0]):wordList.index(sEsEndingWords[0])+1])\n",
        "\n",
        "            if len(sEsEndingWords) == 1 and wordList.index(sEsEndingWords[0]) == len(wordList)-1:\n",
        "              Object = ''\n",
        "            if len(sEsEndingWords) > 1 and wordList.index(sEsEndingWords[0]) not in [0, len(wordList)-1]:\n",
        "              Object = listToSentance(wordList[wordList.index(sEsEndingWords[0])+1:])\n",
        "    \n",
        "    return [Subject, Verb, Object]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ4cioOuouL1",
        "outputId": "663647f5-9b2c-4ff7-e233-fcd22e3f89be"
      },
      "source": [
        "splitSimple()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['He', 'works']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nElPMb73JrOt"
      },
      "source": [
        "## **Driver (for testing) Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MucvJDMGIBO",
        "outputId": "795b3cf9-a6ed-4e75-a280-d6dfd8de4191"
      },
      "source": [
        "def driverFun():\n",
        "  ## Processing Level 1\n",
        "  aSentance = readSentance()\n",
        "  print()\n",
        "  \n",
        "  oneCase = toLower(aSentance)\n",
        "  abbrResolved = resolveAbbr(oneCase)\n",
        "  positiveTense = negationRemover(abbrResolved)\n",
        "\n",
        "  ## Processing Level 2\n",
        "  nonQuestion = removeQuestion(positiveTense)\n",
        "  cleanSentance = removeStops(nonQuestion)\n",
        "  #print(\"Clean sentance: \",cleanSentance,\"\\n\")\n",
        "\n",
        "  ## Processing Level 3\n",
        "  threeOrFourParts,flag = consistsHelpingVerb(cleanSentance)\n",
        "  #print(threeOrFourParts)\n",
        "\n",
        "  ## Processing Level 4\n",
        "  if flag:\n",
        "    sentanceBeg = splitFromBeg(threeOrFourParts[0], True) # true means tense has some HV\n",
        "    fullSentance = []\n",
        "    fullSentance.extend(sentanceBeg)\n",
        "    fullSentance.append(twoParts[1])\n",
        "  else:\n",
        "    fullSentance = threeOrFourParts\n",
        "  \n",
        "  print(fullSentance)\n",
        "\n",
        "\n",
        "##############\n",
        "\n",
        "driverFun()\n",
        "\n",
        "##  \"Charlie hasn't been competin' in flute competitions recently!!!\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a sentance: Every Monday they eat spaghetti for dinner.\n",
            "\n",
            "Interrogative to normal sentance converter is yet to be impleented!\n",
            "\n",
            "['every monday they ', '', 'eat ', 'spaghetti for dinner ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXxiFectrezx",
        "outputId": "d5795032-0a09-4ff7-a09c-4dc19806a693"
      },
      "source": [
        "\n",
        "def consistsHelpingVerb(sentance = \"he goes\"):\n",
        "  ## Helping Verbs List\n",
        "  helpingVerbs = ['is', 'am', 'are', 'was', 'were', 'been', 'be', 'have', 'shall', 'will', 'may', 'can', 'must', 'should', 'would', 'might', 'could', 'do', 'does', 'did', 'has', 'had']\n",
        "  if hasWordsFrom(helpingVerbs, sentance.split(\" \")):\n",
        "    print(\"checking in hv\")\n",
        "    splittedForm = splitOnHelpingVerb(sentance)\n",
        "    return splittedForm,True\n",
        "  else:\n",
        "    print(\"checking in non-hv\")\n",
        "    HV = ''\n",
        "    splittedForm = splitSimple(sentance)\n",
        "    splittedForm.insert(1,HV)\n",
        "    return splittedForm,False\n",
        "\n",
        "\n",
        "consistsHelpingVerb(\"every monday they eat spaghetti for dinner\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checking in non-hv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['every monday they ', '', 'eat ', 'spaghetti for dinner '], False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGAFWqXIsHvl",
        "outputId": "b216144e-469a-4cfa-bd8b-c7dc9093e357"
      },
      "source": [
        "x = [1,2,3,4].insert(2,200)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BMofmnKjDfs"
      },
      "source": [
        "## Storing in Tree\n",
        "\n",
        "**Steps:**  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEFNHPdcjKEg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH3_Apk8xroY"
      },
      "source": [
        "# **Users' Zone**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyI2HAB1yFk_"
      },
      "source": [
        "## Main-Menu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfHAuVHhy9NY"
      },
      "source": [
        "def menu():\n",
        "  # Printing Menu\n",
        "  print(\"\\nMain Menu:\")\n",
        "  print(\"\"\"----------\n",
        "        \\n1. Load Raw Images  \\n2. Create New Album  \\n3. Grab n-th Image \\n4. Print Loaded Images \\n5. Print Newly Created Album \\n\n",
        "        \\n** Any other key to exit!!\\n\n",
        "        \"\"\")\n",
        "  return input(\"Enter your choice: \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es9_NCfcyJ_6"
      },
      "source": [
        "## Main-Function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6wDVKdTtUe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518b0e43-4856-41da-eb3a-a1f82aa02856"
      },
      "source": [
        "### To be Implemented\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  \n",
        "  ## Showing Menu\n",
        "\n",
        "  while (True): \n",
        "    clear_output()\n",
        "    #choice = menu()\n",
        "    \n",
        "    print(\"Yet to be implemented!\\nMeet Soon!!!\")\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yet to be implemented!\n",
            "Meet Soon!!!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}