{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English Sentence Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PbBKO7yB7xZL",
        "izOs7jo4jvp-",
        "E2hF4khWRIIV",
        "nElPMb73JrOt",
        "9BMofmnKjDfs",
        "rH3_Apk8xroY",
        "UyI2HAB1yFk_",
        "Es9_NCfcyJ_6"
      ],
      "toc_visible": true,
      "mount_file_id": "1prLalDT_maKhMli9pm_VXOCr1S6ZDGvA",
      "authorship_tag": "ABX9TyPRbtvt8di+D2wJ5D1FlXNM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravi-prakash1907/Data-Structures-and-Algo/blob/main/Submissions/Group%20Projects/Project3/English_Sentence_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEqW0B7yvl4G"
      },
      "source": [
        "# **Project 3**\n",
        "\n",
        "## English Sentence Generator\n",
        "\n",
        "<!--\n",
        "_**([Final Report Here!!](#))**_\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbBKO7yB7xZL"
      },
      "source": [
        "### _Libraries_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm8H5oQWv0Xx"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foyO7TpHyotA"
      },
      "source": [
        "## Input Text Processing\n",
        "\n",
        "**Steps:**  \n",
        "1. Get Sentance (Input)  \n",
        "2. Convert to Lower/Upper Case  \n",
        "3. Resolve for Abbriviation (ain't, I've, can't...)  \n",
        "4. Remove Negation  \n",
        "5. Resolve for Interrogative  \n",
        "6. Remove Stopping Symbol (. ! ? : ; etc..)\n",
        "7. Split the Sentance and Store in Dictionary  \n",
        "  - _Parts of Sentance:_  \n",
        "    a) Subject  \n",
        "    b) Helping Verb  \n",
        "    c) Verb + Object  \n",
        "\n",
        "_(we can later split **b** in 2-levels and **c** in 2 saperate parts)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNhV9ozDoMah"
      },
      "source": [
        "## List of words to sentance\n",
        "def listToSentance(buildingBlocks):\n",
        "  newSentance = \"\"\n",
        "  for word in buildingBlocks:\n",
        "    newSentance += word + \" \"\n",
        "  \n",
        "  return newSentance[:-1]   # last letter is space (from for-loop)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izOs7jo4jvp-"
      },
      "source": [
        "### Processing Level 1\n",
        "\n",
        "1. Taking Input  \n",
        "2. Converting to Lower Case  \n",
        "3. Resolving for Abbriviation  \n",
        "4. Removing Negation  \n",
        "\n",
        "_(Step 1, 2, 3 and 4)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6odzyxoihyU"
      },
      "source": [
        "## part of text data cleaner\n",
        "def toLower(sentance):\n",
        "  return sentance.lower()\n",
        "\n",
        "\n",
        "# resolving for abbreviations\n",
        "def resolveAbbr(sentance):\n",
        "  if '\\'' in sentance:\n",
        "    splittedSentance = sentance.split(\" \")\n",
        "\n",
        "    for index in range(0, len(splittedSentance)):\n",
        "      word = splittedSentance[index]\n",
        "\n",
        "      # abbriviated 'not'\n",
        "      if word[-3:] == 'n\\'t':\n",
        "        if word == 'can\\'t':\n",
        "          word = 'can not'\n",
        "        elif word == 'ain\\'t':\n",
        "          word = 'are not'  # or 'is not' too in some cases still it'll work for now\n",
        "        elif word == 'won\\'t':\n",
        "          word = 'will not'\n",
        "        elif word == 'shan\\'t':\n",
        "          word = 'shall not'\n",
        "        else:\n",
        "          word = word[:-3] + \" not\"\n",
        "      \n",
        "      # abbriviated 'ing'\n",
        "      if word[-3:] == 'in\\'':\n",
        "        word = word[:-1] + 'g'\n",
        "      \n",
        "      # abbriviated helping verbs\n",
        "      abbrHVerbs = {'m':'am', 's':'is', 're':'are', 'll':'will', 've':'have', 'd':'had'}\n",
        "      if \"'\" in word:\n",
        "        flag = False\n",
        "        brokenWord = word.split('\\'')\n",
        "        for abbr in list(abbrHVerbs.keys()):\n",
        "          if  abbr == brokenWord[1]:\n",
        "            brokenWord[1] = abbrHVerbs[abbr]\n",
        "            flag = True\n",
        "\n",
        "        if flag:\n",
        "          word = listToSentance(brokenWord)\n",
        "        else:\n",
        "          word = brokenWord[0] + '\\'' + brokenWord[1]\n",
        "      \n",
        "      splittedSentance[index] = word\n",
        "\n",
        "    resolvedTense = listToSentance(splittedSentance)\n",
        "    return resolvedTense\n",
        "\n",
        "  return sentance\n",
        "\n",
        "\n",
        "## Later we'll read sntances from some other source(s).\n",
        "def readSentance():\n",
        "  textData = input(\"Enter a sentance: \")\n",
        "  return textData\n",
        "\n",
        "\n",
        "## Removing Negation\n",
        "def negationRemover(sentance):\n",
        "  if 'not' in sentance:\n",
        "    begIndex = sentance.find(\"not\")\n",
        "    sentance = sentance[:begIndex-1] + sentance[begIndex+3:]\n",
        "    sentance = negationRemover(sentance)\n",
        "  return sentance\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2hF4khWRIIV"
      },
      "source": [
        "### Processing Level 2\n",
        "\n",
        "1. Resolving for Interrogatives  \n",
        "2. Remove Stopping Symbol (. ! ? : ; etc..)\n",
        "\n",
        "_(Step 5)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlnX-tBARX2H"
      },
      "source": [
        "## Yet to be implemented\n",
        "def removeQuestion(sentance):\n",
        "  print(\"Interrogative to normal sentance converter is yet to be impleented!\\n\")\n",
        "  return sentance\n",
        "\n",
        "def removeStops(sentance):\n",
        "  if not sentance[-1].isalpha() and not sentance[-1].isdigit():\n",
        "    sentance = removeStops(sentance[:-1])\n",
        "  return sentance"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nElPMb73JrOt"
      },
      "source": [
        "#### **Driver (for testing) Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MucvJDMGIBO",
        "outputId": "c1137416-1127-42fd-ba2d-16ae3d7132ff"
      },
      "source": [
        "def driverFun():\n",
        "  aSentance = readSentance()\n",
        "  print()\n",
        "  \n",
        "  oneCase = toLower(aSentance)\n",
        "  abbrResolved = resolveAbbr(oneCase)\n",
        "  positiveTense = negationRemover(abbrResolved)\n",
        "  nonQuestion = removeQuestion(positiveTense)\n",
        "  cleanSentance = removeStops(nonQuestion)\n",
        "  print(cleanSentance)\n",
        "\n",
        "\n",
        "##############\n",
        "\n",
        "driverFun()\n",
        "\n",
        "##  \"He isn't a bad boy, although he's not ready for singin' for now as it's already 10 O'clock!\""
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a sentance: He isn't a bad boy, although he's not ready for singin' for now as it's already 10 O'clock!\n",
            "\n",
            "Interrogative to normal sentance converter is yet to be impleented!\n",
            "\n",
            "he is a bad boy, although he is ready for singing for now as it is already 10 o'clock\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHuC3HYTRghV"
      },
      "source": [
        "### Processing Level 3\n",
        "\n",
        "**Initial Splitting** _(if consists Helping Verb)_  \n",
        "\n",
        "**Parts of Sentance:**  \n",
        "  - Subject + Helping Verb  \n",
        "  - Verb + Object  \n",
        "\n",
        "\n",
        "_(Step 6.1)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2yKUKwsdfhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8d8931c-e262-413a-bc6f-eeccdf2c23d5"
      },
      "source": [
        "## Building Blocks\n",
        "\n",
        "# splits as:  ['sub + HV', 'verb + obj']\n",
        "def splitOnHelpingVerb(sentance):\n",
        "  ## H.V. to split\n",
        "  firstPriority = ['am', 'is', 'are', 'was', 'were']\n",
        "  secondPriority = ['been', 'be']\n",
        "  thirdPriority = ['have']\n",
        "  forthPriority = ['can', 'has', 'shall', 'will', 'do', 'does', 'did', 'should', 'may', 'might', 'would' 'must', 'could', 'had']\n",
        "\n",
        "  helpingVerbs = [firstPriority, secondPriority, thirdPriority, forthPriority]\n",
        "  initSplit = []\n",
        "  splitted = False\n",
        "  \n",
        "  for priorityList in helpingVerbs:\n",
        "    for helpingVerb in priorityList:\n",
        "      if helpingVerb in sentance:\n",
        "        initSplit = sentance.split(helpingVerb)\n",
        "        initSplit[0] += helpingVerb\n",
        "        splitted = True\n",
        "        break\n",
        "    if splitted:\n",
        "      break\n",
        "  \n",
        "  return initSplit\n",
        "\n",
        "\n",
        "def consistsHelpingVerb(sentance = \"he goes\"):\n",
        "  ## Helping Verbs List\n",
        "  helpingVerbs = ['am', 'is', 'are', 'was', 'were', 'been', 'be', 'can', 'has', 'shall', 'will', 'do', 'does', 'did', 'have', 'should', 'may', 'might', 'would' 'must', 'could', 'had']\n",
        "  for HV in helpingVerbs:\n",
        "    if HV in sentance:\n",
        "      return splitOnHelpingVerb(sentance)\n",
        "  return False\n",
        "\n",
        "#######################################\n",
        "\n",
        "## he is a bad boy, although he is ready for singing for now as it is already 10 o'clock\n",
        "consistsHelpingVerb()\n"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLSf3Sh-fv3y"
      },
      "source": [
        "### Processing Level 4\n",
        "\n",
        "**Secondary Splitting**  \n",
        "\n",
        "_Parts of **Subject + Helping Verb** :_  \n",
        "  - Subject  \n",
        "  - Helping Verb  \n",
        "\n",
        "_Parts of **Verb + Object** :_  \n",
        "  - Verb  \n",
        "  - Object  \n",
        "\n",
        "\n",
        "_(Step 6.2 & 6.3)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7hjK8pwgbFf"
      },
      "source": [
        "## split [\"Sub\", \"helpingVerb / verb / verb+obj\"]\n",
        "def splitFromBeg(sentance, consistsHV = False):\n",
        "  wordList = sentance.split(\" \")\n",
        "  if len(wordList) == 2:\n",
        "    return wordList\n",
        "  elif len(wordList) > 2 and consistsHV:\n",
        "    firstPriority = ['am', 'is', 'are', 'was', 'were']\n",
        "    secondPriority = ['been', 'be']\n",
        "    thirdPriority = ['have']\n",
        "    forthPriority = ['can', 'has', 'shall', 'will', 'do', 'does', 'did', 'should', 'may', 'might', 'would' 'must', 'could', 'had']\n",
        "    \n",
        "    helpingVerbs = [firstPriority, forthPriority, thirdPriority, secondPriority]\n",
        "    begSplitted = []\n",
        "    splitted = False\n",
        "    \n",
        "    for priorityList in helpingVerbs:\n",
        "      for helpingVerb in priorityList:\n",
        "        if helpingVerb in sentance:\n",
        "          begSplitted = sentance.split(helpingVerb)\n",
        "          #HVBegIndex = sentance.find(helpingVerb)\n",
        "          begSplitted[1] = helpingVerb + begSplitted[1]\n",
        "          splitted = True\n",
        "          break\n",
        "      if splitted:\n",
        "        break\n",
        "    return begSplitted\n",
        "  else:\n",
        "    print(\"Yet to be implemented for sentences without HV. (like: 'he goes.')\")"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iatPF9yJiSyD",
        "outputId": "0deee1af-1644-4cb1-91f0-920076d56003"
      },
      "source": [
        "sentance = ['He have been eating', 'a bad boy']\n",
        "splitFromBeg(sentance[0], True)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['He ', 'have been eating']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BMofmnKjDfs"
      },
      "source": [
        "## Storing in Tree\n",
        "\n",
        "**Steps:**  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEFNHPdcjKEg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH3_Apk8xroY"
      },
      "source": [
        "# **Users' Zone**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyI2HAB1yFk_"
      },
      "source": [
        "## Main-Menu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfHAuVHhy9NY"
      },
      "source": [
        "def menu():\n",
        "  # Printing Menu\n",
        "  print(\"\\nMain Menu:\")\n",
        "  print(\"\"\"----------\n",
        "        \\n1. Load Raw Images  \\n2. Create New Album  \\n3. Grab n-th Image \\n4. Print Loaded Images \\n5. Print Newly Created Album \\n\n",
        "        \\n** Any other key to exit!!\\n\n",
        "        \"\"\")\n",
        "  return input(\"Enter your choice: \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es9_NCfcyJ_6"
      },
      "source": [
        "## Main-Function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6wDVKdTtUe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518b0e43-4856-41da-eb3a-a1f82aa02856"
      },
      "source": [
        "### To be Implemented\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  \n",
        "  ## Showing Menu\n",
        "\n",
        "  while (True): \n",
        "    clear_output()\n",
        "    #choice = menu()\n",
        "    \n",
        "    print(\"Yet to be implemented!\\nMeet Soon!!!\")\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yet to be implemented!\n",
            "Meet Soon!!!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}