{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English Sentence Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PbBKO7yB7xZL",
        "E2hF4khWRIIV",
        "KLSf3Sh-fv3y",
        "Wc525NItwsET",
        "IYOWtX8qLEa9",
        "V7Ct6tTkxvx9",
        "rH3_Apk8xroY",
        "UyI2HAB1yFk_",
        "Es9_NCfcyJ_6"
      ],
      "mount_file_id": "1prLalDT_maKhMli9pm_VXOCr1S6ZDGvA",
      "authorship_tag": "ABX9TyOtvU5jxIvlMj834/JBpW61",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravi-prakash1907/Data-Structures-and-Algo/blob/main/Submissions/Group%20Projects/Project3/English_Sentence_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEqW0B7yvl4G"
      },
      "source": [
        "# **Project 3**\n",
        "\n",
        "## English Sentence Generator\n",
        "\n",
        "<!--\n",
        "_**([Final Report Here!!](#))**_\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbBKO7yB7xZL"
      },
      "source": [
        "### _Libraries_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm8H5oQWv0Xx"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import re"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foyO7TpHyotA"
      },
      "source": [
        "## Input Text Processing\n",
        "\n",
        "**Steps:**  \n",
        "1. Get Sentance (Input)  \n",
        "2. Convert to Lower/Upper Case  \n",
        "3. Resolve for Abbriviation  \n",
        "4. Remove Negation  \n",
        "5. Resolve for Interrogative  \n",
        "6. Remove Stopping Symbol (. ! ? : ; etc..)  \n",
        "7. Split into multiple sentances on Conjunctions\n",
        "8. Split the Sentance and Store in Dictionary  \n",
        "  - _Parts of Sentance:_  \n",
        "    a) Subject  \n",
        "    b) Helping Verb  \n",
        "    c) Verb  \n",
        "    d) Object  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNhV9ozDoMah"
      },
      "source": [
        "## returns elements of 'allWords' that are in 'findIn'\n",
        "def hasWordsFrom(allWords, findIn):\n",
        "  found = []\n",
        "  for searched in allWords:\n",
        "    if searched in findIn:\n",
        "      found.append(searched)\n",
        "  if len(found) > 0:\n",
        "    return found\n",
        "  return False\n",
        "\n",
        "## remove unnecessary space in beg or end of string and emptyStrings too\n",
        "def removeBlanks(wordGroup):\n",
        "  #while '' in wordGroup:\n",
        "    #wordGroup.remove('')\n",
        "\n",
        "  for wordIndex in range(len(wordGroup)):\n",
        "    if wordGroup[wordIndex] == '':\n",
        "      continue\n",
        "    while wordGroup[wordIndex][0] == \" \":\n",
        "      wordGroup[wordIndex] = wordGroup[wordIndex][1:]\n",
        "    while wordGroup[wordIndex][-1] == \" \":\n",
        "      wordGroup[wordIndex] = wordGroup[wordIndex][:-1]\n",
        "  \n",
        "  return wordGroup\n",
        "\n",
        "## List of words to sentance\n",
        "def listToSentance(buildingBlocks):\n",
        "  buildingBlocks = removeBlanks(buildingBlocks)\n",
        "  newSentance = \"\"\n",
        "  for word in buildingBlocks:\n",
        "    newSentance += word + \" \"\n",
        "  return newSentance[:-1]   # last letter is space (from for-loop)  "
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izOs7jo4jvp-"
      },
      "source": [
        "### Processing Level 1\n",
        "\n",
        "1. Taking Input  \n",
        "2. Converting to Lower Case  \n",
        "3. Resolving for Abbriviation  \n",
        "4. Removing Negation  \n",
        "\n",
        "_(Step 1, 2, 3 and 4)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6odzyxoihyU"
      },
      "source": [
        "## part of text data cleaner\n",
        "def toLower(sentance):\n",
        "  return sentance.lower()\n",
        "\n",
        "\n",
        "# resolving for abbreviations\n",
        "def resolveAbbr(sentance):\n",
        "  if '\\'' in sentance:\n",
        "    splittedSentance = sentance.split(\" \")\n",
        "\n",
        "    for index in range(0, len(splittedSentance)):\n",
        "      word = splittedSentance[index]\n",
        "\n",
        "      # abbriviated 'not'\n",
        "      if word[-3:] == 'n\\'t':\n",
        "        if word == 'can\\'t':\n",
        "          word = 'can not'\n",
        "        elif word == 'ain\\'t':\n",
        "          word = 'are not'  # or 'is not' too in some cases still it'll work for now\n",
        "        elif word == 'won\\'t':\n",
        "          word = 'will not'\n",
        "        elif word == 'shan\\'t':\n",
        "          word = 'shall not'\n",
        "        else:\n",
        "          word = word[:-3] + \" not\"\n",
        "      \n",
        "      # abbriviated 'ing'\n",
        "      if word[-3:] == 'in\\'':\n",
        "        word = word[:-1] + 'g'\n",
        "      \n",
        "      # abbriviated helping verbs\n",
        "      abbrHVerbs = {'m':'am', 's':'is', 're':'are', 'll':'will', 've':'have', 'd':'had'}\n",
        "      if \"'\" in word:\n",
        "        flag = False\n",
        "        brokenWord = word.split('\\'')\n",
        "        for abbr in list(abbrHVerbs.keys()):\n",
        "          if  abbr == brokenWord[1]:\n",
        "            brokenWord[1] = abbrHVerbs[abbr]\n",
        "            flag = True\n",
        "\n",
        "        if flag:\n",
        "          word = listToSentance(brokenWord)\n",
        "        else:\n",
        "          word = brokenWord[0] + '\\'' + brokenWord[1]\n",
        "      \n",
        "      splittedSentance[index] = word\n",
        "\n",
        "    resolvedTense = listToSentance(splittedSentance)\n",
        "    return resolvedTense\n",
        "\n",
        "  return sentance\n",
        "\n",
        "\n",
        "## Later we'll read sntances from some other source(s).\n",
        "def readSentance():\n",
        "  textData = input(\"Enter a sentance: \")\n",
        "  return textData\n",
        "\n",
        "\n",
        "## Removing Negation\n",
        "def negationRemover(sentance):\n",
        "  if 'not' in sentance:\n",
        "    begIndex = sentance.find(\"not\")\n",
        "    sentance = sentance[:begIndex-1] + sentance[begIndex+3:]\n",
        "    sentance = negationRemover(sentance)\n",
        "  return sentance\n"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxKOmFRdrfVf"
      },
      "source": [
        "### Processing Level 2.1\n",
        "\n",
        "_Split mutiple sentances on Conjunctions:_  \n",
        "  - That  \n",
        "  - But  \n",
        "  - While  \n",
        "  - Meanwhile  \n",
        "  - Still\n",
        "  - Before  \n",
        "\n",
        "_Remove Interjections:_  \n",
        "  - oh!  \n",
        "  - yess!!  \n",
        "  etc..  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y5QVHGitBYC"
      },
      "source": [
        "articles = ['a', 'an', 'the']\n",
        "pluralPronouns = ['some', 'any', 'these', 'their', 'our', 'those', 'them', 'they', 'you', 'i', 'we']\n",
        "singlelPronouns = ['he', 'she','his', 'her', 'my', 'this', 'that', 'it']\n",
        "conjunctions = ['that', 'but', 'while', 'meanwhile', 'still', 'before']\n",
        "allHelpingVerbs = ['is', 'am', 'are', 'was', 'were', 'been', 'be', 'have', 'shall', 'will', 'may', 'can', 'must', 'should', 'would', 'might', 'could', 'do', 'does', 'did', 'has', 'had']"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4ejdz1rsXS7"
      },
      "source": [
        "## to remove interjections\n",
        "def removeInterjections(sentance):\n",
        "  wordList = sentance.split(\" \")\n",
        "  foundInterjections = []\n",
        "  for word in wordList:\n",
        "    if word[-2:] == \"!!\" or word[-1] == \"!\":\n",
        "      foundInterjections.append(word)\n",
        "  \n",
        "  # removing found interjections\n",
        "  for interjection in foundInterjections:\n",
        "    wordList.remove(interjection)\n",
        "  \n",
        "  newSentence = listToSentance(wordList)\n",
        "  return newSentence\n",
        "\n",
        "## to extract only one sentance from grouped form\n",
        "def multipleSentances(sentance):\n",
        "  wordList = sentance.split(\" \")\n",
        "  foundConjunctions = hasWordsFrom(conjunctions, wordList)\n",
        "\n",
        "  if foundConjunctions:\n",
        "    twoSubSentences = sentance.split(foundConjunctions[0])\n",
        "    twoSubSentences = removeBlanks(twoSubSentences)\n",
        "    commonSub = []\n",
        "    commonSub.extend(articles)\n",
        "    commonSub.extend(pluralPronouns)\n",
        "    commonSub.extend(singlelPronouns)\n",
        "    \n",
        "    hasDualSentance = False\n",
        "    for thisSubSentance in twoSubSentences:\n",
        "      if hasWordsFrom(allHelpingVerbs, thisSubSentance) or hasWordsFrom(commonSub, thisSubSentance):\n",
        "        hasDualSentance = True\n",
        "      else:\n",
        "        hasDualSentance = False\n",
        "      \n",
        "    if hasDualSentance:\n",
        "      return twoSubSentences[0]\n",
        "    \n",
        "  return sentance\n"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mqKDqtnswM28",
        "outputId": "29705953-3ad1-4fcb-b444-d865d5572fbd"
      },
      "source": [
        ""
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'We won'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2hF4khWRIIV"
      },
      "source": [
        "### Processing Level 2\n",
        "\n",
        "1. Resolving for Interrogatives  \n",
        "2. Remove Stopping Symbol (. ! ? : ; etc..)\n",
        "\n",
        "_(Step 5, 6)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlnX-tBARX2H"
      },
      "source": [
        "## Yet to be implemented\n",
        "def removeQuestion(sentance):\n",
        "  print(\"Interrogative to normal sentance converter is yet to be impleented!\\n\")\n",
        "  return sentance\n",
        "\n",
        "def removeStops(sentance):\n",
        "  if not sentance[-1].isalpha() and not sentance[-1].isdigit():\n",
        "    sentance = removeStops(sentance[:-1])\n",
        "  return sentance"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHuC3HYTRghV"
      },
      "source": [
        "### Processing Level 3\n",
        "\n",
        "**Initial Splitting** _(if consists Helping Verb)_  \n",
        "\n",
        "* ```['sub', 'HV', 'verb', 'obj']```\n",
        "* ```['sub', 'HV', 'obj']```\n",
        "\n",
        "_(Step 8.1)_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLSf3Sh-fv3y"
      },
      "source": [
        "#### **Processing Level 3.1**\n",
        "\n",
        "Secondary Splitting  \n",
        "\n",
        "Parts of _Subject + Helping Verb_:\n",
        "  - Subject  \n",
        "  - Helping Verb  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7hjK8pwgbFf"
      },
      "source": [
        "## split [\"Sub\", \"helpingVerb / verb / verb+obj\"]\n",
        "def splitFromBeg(sentance, consistsHV = False):  # rename 'consistsHV'  --->  'helpingVerbs'\n",
        "  if len(sentance.split(\" \")) == 2:\n",
        "    return sentance.split(\" \")\n",
        "  \n",
        "  elif len(sentance.split(\" \")) > 2 and consistsHV:\n",
        "    helpingVerbs = consistsHV\n",
        "\n",
        "    begSplitted = []\n",
        "    splitted = False\n",
        "    \n",
        "    for priorityList in helpingVerbs:\n",
        "      for helpingVerb in priorityList:\n",
        "        if helpingVerb in sentance:\n",
        "          begSplitted = sentance.split(helpingVerb)\n",
        "          begSplitted[1] = helpingVerb + begSplitted[1]\n",
        "          splitted = True\n",
        "          break\n",
        "      if splitted:\n",
        "        break\n",
        "    return begSplitted"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc525NItwsET"
      },
      "source": [
        "#### **Processing Level 3.2**\n",
        "\n",
        "Secondary Splitting of Object Field \n",
        "_(for sentences with HV)_  \n",
        "\n",
        "_Parts of **Verb + Object** :_  \n",
        "  - Verb  \n",
        "  - Object  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuqDBwXixWHk"
      },
      "source": [
        "def splitFromEnd(hVerb = 'was', objectPart = 'very thirsty'):\n",
        "  specialHV = ['is', 'am', 'are', 'was', 'were', 'been', 'be']\n",
        "  #seconfPriority = ['shall', 'will', 'may', 'can', 'must', 'should', 'would', 'might', 'could', 'do', 'does', 'did', 'has', 'have', 'had']\n",
        "  Verb = Object = ''\n",
        "  gotVerb = False\n",
        "\n",
        "  splittedObj = objectPart.split(\" \")\n",
        "  hVerb = hVerb.split(\" \")\n",
        "\n",
        "  if hVerb[-1] in specialHV:\n",
        "    for index in range(len(splittedObj)):\n",
        "      if splittedObj[index][-3:] == 'ing':\n",
        "        Verb = listToSentance(splittedObj[:index+1])\n",
        "        gotVerb = True\n",
        "        if len(splittedObj) > index+1:\n",
        "          Object = listToSentance(splittedObj[index+1:])\n",
        "        break\n",
        "    if gotVerb:\n",
        "      Object = listToSentance(splittedObj)\n",
        "    else:\n",
        "      Object = objectPart\n",
        "  else:\n",
        "    Verb = splittedObj[0]\n",
        "    if len(splittedObj) > 1:\n",
        "      Object = listToSentance(splittedObj[1:])\n",
        "  \n",
        "  return [Verb, Object]\n"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYOWtX8qLEa9"
      },
      "source": [
        "#### **Calls Above 2 Functions on:**  \n",
        "\n",
        "```['sub + HV', 'verb + obj']```\n",
        "\n",
        "Parts of Sentance:  \n",
        "  - Subject + Helping Verb  \n",
        "  - Verb + Object  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2yKUKwsdfhC"
      },
      "source": [
        "## Building Blocks\n",
        "\n",
        "# splits as:  ['sub + HV', 'verb + obj']\n",
        "def splitOnHelpingVerb(sentance):\n",
        "  ## H.V. to split\n",
        "  firstPriority = ['is', 'am', 'are', 'was', 'were']\n",
        "  secondPriority = ['been', 'be']\n",
        "  thirdPriority = ['have']\n",
        "  forthPriority = ['shall', 'will', 'may', 'can', 'must', 'should', 'would', 'might', 'could', 'do', 'does', 'did', 'has', 'had']\n",
        "\n",
        "  helpingVerbs = [firstPriority, secondPriority, thirdPriority, forthPriority]\n",
        "  initSplit = []\n",
        "  splitted = False\n",
        "  \n",
        "  for priorityList in helpingVerbs:\n",
        "    for helpingVerb in priorityList:\n",
        "      if helpingVerb in sentance:\n",
        "        initSplit = sentance.split(helpingVerb)\n",
        "        initSplit[0] += helpingVerb\n",
        "        splitted = True\n",
        "        break\n",
        "    if splitted:\n",
        "      break\n",
        "  \n",
        "  initSplit = removeBlanks(initSplit)\n",
        "\n",
        "  ####  'sub + HV'  ---->   ['sub', 'HV']\n",
        "  subNHVSplit = splitFromBeg(initSplit[0], helpingVerbs[::-1])\n",
        "  subNHVSplit = removeBlanks(subNHVSplit)\n",
        "\n",
        "  ####  'verb + obj'  ----> ['verb', 'obj']\n",
        "  verbNObjSplit = splitFromEnd(subNHVSplit[1], initSplit[1])\n",
        "  verbNObjSplit = removeBlanks(verbNObjSplit)\n",
        "\n",
        "  ###\n",
        "  splittedSentences = []\n",
        "  splittedSentences.extend(subNHVSplit)\n",
        "  splittedSentences.extend(verbNObjSplit)\n",
        "\n",
        "  return splittedSentences\n"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWXypml1hnRE"
      },
      "source": [
        "### Processing Level 4\n",
        "\n",
        "**Initial Splitting** _(without Helping Verb)_  \n",
        "\n",
        "* ```['sub', 'verb', 'obj']```\n",
        "* ```['sub', 'obj']```\n",
        "\n",
        "_(Step 8.2)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRuOg8zSiITu"
      },
      "source": [
        "def splitSimple(sentance = \"He works\"):\n",
        "  wordList = sentance.split(\" \")\n",
        "  totalWords = len(wordList)\n",
        "  Subject = Verb = Object = ''\n",
        "\n",
        "  articles = ['a', 'an', 'the']\n",
        "  pluralPronouns = ['some', 'any', 'these', 'their', 'our', 'those', 'them', 'they', 'you', 'i', 'we']\n",
        "  singlelPronouns = ['he', 'she','his', 'her', 'my', 'this', 'that', 'it']  # Tackel more at :   http://grammar.ccc.commnet.edu/grammar/determiners/determiners.htm#:~:text=These%20categories%20of%20determiners%20are,any%2C%20etc.)%3B%20and%20demonstrative\n",
        "  \n",
        "  if totalWords <= 2:\n",
        "    Subject = wordList[0]\n",
        "    if (Subject in singlelPronouns) and (wordList[1][-2:] not in ['s', 'es']):\n",
        "      Object = wordList[1]\n",
        "    else:\n",
        "      Verb = wordList[1]\n",
        "  else:\n",
        "    # checking for Simple Past\n",
        "    if sentance[-2:] == 'ed' or 'ed ' in sentance:\n",
        "      for word in wordList:\n",
        "        if 'ed' in word or 'ed ' in word:\n",
        "          Subject = listToSentance(wordList[:wordList.index(word)])\n",
        "          Verb = word\n",
        "          Object = listToSentance(wordList[wordList.index(word)+1:])\n",
        "          break\n",
        "      \n",
        "    # checking for Simple Present (mainly)\n",
        "    else:\n",
        "      sEsEndingWords = []\n",
        "      for word in wordList:\n",
        "        if (word[-2:] == 'es') or (word[-1] == 's' and not (word[-2:] == 'us' or word[-2:] == 'ss')):\n",
        "          sEsEndingWords.append(word)\n",
        "\n",
        "      usedArticles = hasWordsFrom(articles, wordList)\n",
        "\n",
        "      # if consisits articles\n",
        "      if usedArticles:\n",
        "        if wordList[0] in articles and len(sEsEndingWords) == 1:\n",
        "          wordList.remove(wordList[0])\n",
        "          totalWords -= 1\n",
        "          subEndIndex = wordList.index(sEsEndingWords[0])\n",
        "          if sEsEndingWords[0] == wordList[0]:\n",
        "            Subject = listToSentance(wordList[:subEndIndex+1])\n",
        "            Verb = listToSentance(wordList[subEndIndex+1:])    # includes object\n",
        "            Object = Verb # includes verb\n",
        "          else:\n",
        "            Subject = listToSentance(wordList[:subEndIndex])\n",
        "            Verb = sEsEndingWords[0]\n",
        "            Object = listToSentance(wordList[subEndIndex:])\n",
        "        else:\n",
        "          objBegIndex = wordList.index(usedArticles[0])\n",
        "          singleSub = hasWordsFrom(singlelPronouns, wordList)\n",
        "          if singleSub:\n",
        "            subEndIndex = wordList.index(singleSub[0]) + 1\n",
        "            Subject = listToSentance(wordList[:subEndIndex])\n",
        "            Verb = wordList[subEndIndex]\n",
        "            Object = listToSentance(wordList[objBegIndex:])\n",
        "          else:\n",
        "            Subject = listToSentance(wordList[:objBegIndex-1])\n",
        "            Verb = wordList[objBegIndex-1]\n",
        "            Object = listToSentance(wordList[objBegIndex:])\n",
        "      \n",
        "      else:\n",
        "        if len(sEsEndingWords) == 0:\n",
        "          pluralSub = hasWordsFrom(pluralPronouns, wordList)\n",
        "          if pluralSub:\n",
        "            subEndIndex = wordList.index(pluralSub[0]) + 1\n",
        "          elif ' and ' in sentance:\n",
        "            subEndIndex = wordList.index('and') + 1\n",
        "          else:\n",
        "            subEndIndex = 1\n",
        "          Subject = listToSentance(wordList[:subEndIndex])\n",
        "          Verb = listToSentance(wordList[subEndIndex:subEndIndex+1])    # may includes object\n",
        "          Object = listToSentance(wordList[subEndIndex+1:])  # may includes verb\n",
        "        else:\n",
        "          if wordList.index(sEsEndingWords[0]) == 0:\n",
        "            Subject = listToSentance(wordList[:1])\n",
        "            Verb = listToSentance(wordList[1:2])    # includes object\n",
        "            Object = listToSentance(wordList[2:]) # includes verb\n",
        "          else:\n",
        "            singleSub = hasWordsFrom(singlelPronouns, wordList)\n",
        "            if singleSub:\n",
        "              subEndIndex = wordList.index(singleSub[0]) + 1\n",
        "            else:\n",
        "              subEndIndex = 1\n",
        "            Subject = listToSentance(wordList[:subEndIndex])\n",
        "            Verb = listToSentance(wordList[wordList.index(sEsEndingWords[0]):wordList.index(sEsEndingWords[0])+1])\n",
        "\n",
        "            if len(sEsEndingWords) == 1 and wordList.index(sEsEndingWords[0]) == len(wordList)-1:\n",
        "              Object = ''\n",
        "            if len(sEsEndingWords) > 1 and wordList.index(sEsEndingWords[0]) not in [0, len(wordList)-1]:\n",
        "              Object = listToSentance(wordList[wordList.index(sEsEndingWords[0])+1:])\n",
        "    \n",
        "  return [Subject, Verb, Object]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7Ct6tTkxvx9"
      },
      "source": [
        "### Processing Level 5\n",
        "\n",
        "_Splitting based on the type of sentence_  \n",
        "\n",
        "**Strusture**  \n",
        "\n",
        "* ```['Subject', 'Helping Verb', 'Verb', 'Object']```\n",
        "\n",
        "_(in some cases, few of the parts can be blank)_  \n",
        "\n",
        "_(Step 8)_  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_BKg9d-xy8G"
      },
      "source": [
        "def consistsHelpingVerb(sentance = \"he goes\"):\n",
        "  ## Helping Verbs List\n",
        "  allHelpingVerbs = ['is', 'am', 'are', 'was', 'were', 'been', 'be', 'have', 'shall', 'will', 'may', 'can', 'must', 'should', 'would', 'might', 'could', 'do', 'does', 'did', 'has', 'had']\n",
        "  if hasWordsFrom(allHelpingVerbs, sentance.split(\" \")):\n",
        "    splittedForm = splitOnHelpingVerb(sentance)\n",
        "    return splittedForm\n",
        "  else:\n",
        "    HV = ''\n",
        "    splittedForm = splitSimple(sentance)\n",
        "    splittedForm.insert(1,HV)\n",
        "    return splittedForm\n"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nElPMb73JrOt"
      },
      "source": [
        "## **Driver (for testing) Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MucvJDMGIBO",
        "outputId": "7648d398-509d-4bb4-b87e-40e81f4552fb"
      },
      "source": [
        "def driverFun():\n",
        "  ## Processing Level 1\n",
        "  aSentance = readSentance()\n",
        "  print()\n",
        "  \n",
        "  oneCase = toLower(aSentance)\n",
        "  abbrResolved = resolveAbbr(oneCase)\n",
        "  positiveTense = negationRemover(abbrResolved)\n",
        "\n",
        "  ## Processing Level 2\n",
        "  nonQuestion = removeQuestion(positiveTense)\n",
        "  cleanSentance = removeStops(nonQuestion)\n",
        "\n",
        "  interjectionRemoval = removeInterjections(cleanSentance)\n",
        "  extractedSentence = multipleSentances(interjectionRemoval)\n",
        "  print(extractedSentence)\n",
        "  ## Processing Level 3\n",
        "  fullSentance = consistsHelpingVerb(extractedSentence)    \n",
        "  print(fullSentance)\n",
        "\n",
        "\n",
        "##############\n",
        "\n",
        "driverFun()\n",
        "\n",
        "##  Charlie hasn't been competin' in flute competitions recently!!!\n",
        "##  Every Monday they eat spaghetti for dinner."
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a sentance: Crikey! You think before you speak.\n",
            "\n",
            "Interrogative to normal sentance converter is yet to be impleented!\n",
            "\n",
            "you think\n",
            "\n",
            "Thes sen. has total 2 words!!\n",
            " ['you', 'think'] \n",
            "\n",
            "['you', '', 'think', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BMofmnKjDfs"
      },
      "source": [
        "## Storing in Tree\n",
        "\n",
        "**Steps:**  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEFNHPdcjKEg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH3_Apk8xroY"
      },
      "source": [
        "# **Users' Zone**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyI2HAB1yFk_"
      },
      "source": [
        "## Main-Menu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfHAuVHhy9NY"
      },
      "source": [
        "def menu():\n",
        "  # Printing Menu\n",
        "  print(\"\\nMain Menu:\")\n",
        "  print(\"\"\"----------\n",
        "        \\n1. Load Raw Images  \\n2. Create New Album  \\n3. Grab n-th Image \\n4. Print Loaded Images \\n5. Print Newly Created Album \\n\n",
        "        \\n** Any other key to exit!!\\n\n",
        "        \"\"\")\n",
        "  return input(\"Enter your choice: \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es9_NCfcyJ_6"
      },
      "source": [
        "## Main-Function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6wDVKdTtUe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518b0e43-4856-41da-eb3a-a1f82aa02856"
      },
      "source": [
        "### To be Implemented\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  \n",
        "  ## Showing Menu\n",
        "\n",
        "  while (True): \n",
        "    clear_output()\n",
        "    #choice = menu()\n",
        "    \n",
        "    print(\"Yet to be implemented!\\nMeet Soon!!!\")\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yet to be implemented!\n",
            "Meet Soon!!!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}